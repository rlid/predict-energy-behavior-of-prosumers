{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:55.657555Z",
     "start_time": "2023-12-14T09:48:55.650883Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "class MockApi:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        YOU MUST UPDATE THE FIRST THREE LINES of this method.\n",
    "        They've been intentionally left in an invalid state.\n",
    "\n",
    "        Variables to set:\n",
    "            input_paths: a list of two or more paths to the csv files to be served\n",
    "            group_id_column: the column that identifies which groups of rows the API should serve.\n",
    "                A call to iter_test serves all rows of all dataframes with the current group ID value.\n",
    "            export_group_id_column: if true, the dataframes iter_test serves will include the group_id_column values.\n",
    "        '''\n",
    "        self.input_paths: Sequence[str] = ['downloads/example_test_files/test.csv',\n",
    "                                   'downloads/example_test_files/revealed_targets.csv',\n",
    "                                   'downloads/example_test_files/client.csv',\n",
    "                                   'downloads/example_test_files/historical_weather.csv',\n",
    "                                   'downloads/example_test_files/forecast_weather.csv',\n",
    "                                   'downloads/example_test_files/electricity_prices.csv',\n",
    "                                   'downloads/example_test_files/gas_prices.csv',\n",
    "                                   'downloads/example_test_files/sample_submission.csv']\n",
    "        self.group_id_column: str = 'data_block_id'\n",
    "        self.export_group_id_column: bool = False\n",
    "        # iter_test is only designed to support at least two dataframes, such as test and sample_submission\n",
    "        assert len(self.input_paths) >= 2\n",
    "\n",
    "        self._status = 'initialized'\n",
    "        self.predictions = []\n",
    "\n",
    "    def iter_test(self) -> Tuple[pd.DataFrame]:\n",
    "        '''\n",
    "        Loads all of the dataframes specified in self.input_paths,\n",
    "        then yields all rows in those dataframes that equal the current self.group_id_column value.\n",
    "        '''\n",
    "        if self._status != 'initialized':\n",
    "\n",
    "            raise Exception('WARNING: the real API can only iterate over `iter_test()` once.')\n",
    "\n",
    "        dataframes = []\n",
    "        for pth in self.input_paths:\n",
    "            dataframes.append(pd.read_csv(pth, low_memory=False))\n",
    "        group_order = dataframes[0][self.group_id_column].drop_duplicates().tolist()\n",
    "        dataframes = [df.set_index(self.group_id_column) for df in dataframes]\n",
    "\n",
    "        for group_id in group_order:\n",
    "            self._status = 'prediction_needed'\n",
    "            current_data = []\n",
    "            for df in dataframes:\n",
    "                cur_df = df.loc[group_id].copy()\n",
    "                # returning single line dataframes from df.loc requires special handling\n",
    "                if not isinstance(cur_df, pd.DataFrame):\n",
    "                    cur_df = pd.DataFrame({a: b for a, b in zip(cur_df.index.values, cur_df.values)}, index=[group_id])\n",
    "                    cur_df.index.name = self.group_id_column\n",
    "                cur_df = cur_df.reset_index(drop=not(self.export_group_id_column))\n",
    "                current_data.append(cur_df)\n",
    "            yield tuple(current_data)\n",
    "\n",
    "            while self._status != 'prediction_received':\n",
    "                print('You must call `predict()` successfully before you can continue with `iter_test()`', flush=True)\n",
    "                yield None\n",
    "\n",
    "        with open('submission.csv', 'w') as f_open:\n",
    "            pd.concat(self.predictions).to_csv(f_open, index=False)\n",
    "        self._status = 'finished'\n",
    "\n",
    "    def predict(self, user_predictions: pd.DataFrame):\n",
    "        '''\n",
    "        Accepts and stores the user's predictions and unlocks iter_test once that is done\n",
    "        '''\n",
    "        if self._status == 'finished':\n",
    "            raise Exception('You have already made predictions for the full test set.')\n",
    "        if self._status != 'prediction_needed':\n",
    "            raise Exception('You must get the next test sample from `iter_test()` first.')\n",
    "        if not isinstance(user_predictions, pd.DataFrame):\n",
    "            raise Exception('You must provide a DataFrame.')\n",
    "\n",
    "        self.predictions.append(user_predictions)\n",
    "        self._status = 'prediction_received'\n",
    "\n",
    "def make_env():\n",
    "    return MockApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def naive_predict(test_row, revealed_targets):\n",
    "    last_known = revealed_targets[(revealed_targets.is_consumption == test_row.is_consumption) &\n",
    "                                  (revealed_targets.prediction_unit_id == test_row.prediction_unit_id) &\n",
    "                                  (revealed_targets.datetime <= test_row.prediction_datetime - datetime.timedelta(days=2))]\n",
    "    \n",
    "    last_known = last_known[last_known.datetime == last_known.datetime.max()]\n",
    "    \n",
    "    if len(last_known) == 0:\n",
    "        last_known = 0\n",
    "    else:\n",
    "        last_known = last_known.target.mean()\n",
    "    return last_known\n",
    "\n",
    "def naive_predict_batch(test_batch, revealed_targets):\n",
    "    target_series = test_batch.apply(lambda test_row: naive_predict(test_row, revealed_targets), axis=1)\n",
    "    target_series.name = 'target'\n",
    "    predict = pd.concat([test_batch['row_id'], target_series], axis=1)\n",
    "    predict.set_index('row_id', inplace=True)\n",
    "    return predict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:55.668080Z",
     "start_time": "2023-12-14T09:48:55.656054Z"
    }
   },
   "id": "2cd2310e1917f600"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3120 3168\n",
      "3120 3168\n",
      "3120 3120\n",
      "3120 3120\n"
     ]
    }
   ],
   "source": [
    "env = make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "count = 0\n",
    "batch_prediction = None\n",
    "for (test, revealed_targets, client, historical_weather,\n",
    "     forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "    \n",
    "    test['prediction_datetime'] = pd.to_datetime(test['prediction_datetime'])\n",
    "    revealed_targets['datetime'] = pd.to_datetime(revealed_targets['datetime'])\n",
    "    \n",
    "    print(len(test), len(revealed_targets))\n",
    "    \n",
    "    batch_prediction = naive_predict_batch(test, revealed_targets)\n",
    "    sample_prediction['target'] = 0\n",
    "    env.predict(batch_prediction)\n",
    "    count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:59.491964Z",
     "start_time": "2023-12-14T09:48:55.659634Z"
    }
   },
   "id": "6b3d4502ea85a9a"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3120\n",
      "             target\n",
      "count   3120.000000\n",
      "mean     397.055628\n",
      "std     1065.377391\n",
      "min        0.000000\n",
      "25%       10.917750\n",
      "50%       70.727000\n",
      "75%      334.855000\n",
      "max    10689.082000\n",
      "3120\n",
      "             target\n",
      "count   3120.000000\n",
      "mean     384.236975\n",
      "std     1039.807390\n",
      "min        0.000000\n",
      "25%       11.021250\n",
      "50%       63.564000\n",
      "75%      284.275000\n",
      "max    11013.487000\n",
      "3120\n",
      "             target\n",
      "count   3120.000000\n",
      "mean     378.323915\n",
      "std     1010.882205\n",
      "min        0.000000\n",
      "25%        9.075500\n",
      "50%       61.553000\n",
      "75%      276.308000\n",
      "max    10265.362000\n",
      "3120\n",
      "             target\n",
      "count   3120.000000\n",
      "mean     392.325769\n",
      "std     1066.244326\n",
      "min        0.000000\n",
      "25%        9.610000\n",
      "50%       65.132000\n",
      "75%      328.118750\n",
      "max    11146.496000\n"
     ]
    }
   ],
   "source": [
    "for prediction in env.predictions:\n",
    "    print(len(prediction))\n",
    "    print(prediction.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:59.499059Z",
     "start_time": "2023-12-14T09:48:59.493463Z"
    }
   },
   "id": "9257ca750d73892"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "          target\nrow_id          \n2015232    2.073\n2015233  503.735\n2015234    0.000\n2015235    4.986\n2015236   23.590\n...          ...\n2018347  188.167\n2018348    0.000\n2018349   31.484\n2018350    0.000\n2018351  177.056\n\n[3120 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>row_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015232</th>\n      <td>2.073</td>\n    </tr>\n    <tr>\n      <th>2015233</th>\n      <td>503.735</td>\n    </tr>\n    <tr>\n      <th>2015234</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2015235</th>\n      <td>4.986</td>\n    </tr>\n    <tr>\n      <th>2015236</th>\n      <td>23.590</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018347</th>\n      <td>188.167</td>\n    </tr>\n    <tr>\n      <th>2018348</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018349</th>\n      <td>31.484</td>\n    </tr>\n    <tr>\n      <th>2018350</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2018351</th>\n      <td>177.056</td>\n    </tr>\n  </tbody>\n</table>\n<p>3120 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:59.502554Z",
     "start_time": "2023-12-14T09:48:59.500380Z"
    }
   },
   "id": "a0268181810d989c"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T09:48:59.504234Z",
     "start_time": "2023-12-14T09:48:59.502691Z"
    }
   },
   "id": "7b2ce4e2b190584d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
