{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:37.698556425Z",
     "start_time": "2023-12-14T12:46:37.654977693Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "class MockApi:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        YOU MUST UPDATE THE FIRST THREE LINES of this method.\n",
    "        They've been intentionally left in an invalid state.\n",
    "\n",
    "        Variables to set:\n",
    "            input_paths: a list of two or more paths to the csv files to be served\n",
    "            group_id_column: the column that identifies which groups of rows the API should serve.\n",
    "                A call to iter_test serves all rows of all dataframes with the current group ID value.\n",
    "            export_group_id_column: if true, the dataframes iter_test serves will include the group_id_column values.\n",
    "        \"\"\"\n",
    "        self.input_paths: Sequence[str] = ['downloads/example_test_files/test.csv',\n",
    "                                   'downloads/example_test_files/revealed_targets.csv',\n",
    "                                   'downloads/example_test_files/client.csv',\n",
    "                                   'downloads/example_test_files/historical_weather.csv',\n",
    "                                   'downloads/example_test_files/forecast_weather.csv',\n",
    "                                   'downloads/example_test_files/electricity_prices.csv',\n",
    "                                   'downloads/example_test_files/gas_prices.csv',\n",
    "                                   'downloads/example_test_files/sample_submission.csv']\n",
    "        self.group_id_column: str = 'data_block_id'\n",
    "        self.export_group_id_column: bool = False\n",
    "        # iter_test is only designed to support at least two dataframes, such as test and sample_submission\n",
    "        assert len(self.input_paths) >= 2\n",
    "\n",
    "        self._status = 'initialized'\n",
    "        self.predictions = []\n",
    "\n",
    "    def iter_test(self) -> Tuple[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Loads all the dataframes specified in self.input_paths,\n",
    "        then yields all rows in those dataframes that equal the current self.group_id_column value.\n",
    "        \"\"\"\n",
    "        if self._status != 'initialized':\n",
    "\n",
    "            raise Exception('WARNING: the real API can only iterate over `iter_test()` once.')\n",
    "\n",
    "        dataframes = []\n",
    "        for pth in self.input_paths:\n",
    "            df = pd.read_csv(pth, low_memory=False)\n",
    "            for column in df.columns:\n",
    "                if 'date' in column:\n",
    "                    print(f'Transforming {pth}[{column}] from {df[column].dtype} to datetime...')\n",
    "                    if 'forecast' in pth:\n",
    "                        print(f'Stripping incorrect timezone adjustments')\n",
    "                        df[column] = df[column].str[:-6]\n",
    "                    df[column] = pd.to_datetime(df[column], utc=False).dt.tz_localize('Europe/Tallinn')\n",
    "                    \n",
    "            dataframes.append(df)\n",
    "        group_order = dataframes[0][self.group_id_column].drop_duplicates().tolist()\n",
    "        dataframes = [df.set_index(self.group_id_column) for df in dataframes]\n",
    "\n",
    "        for group_id in group_order:\n",
    "            self._status = 'prediction_needed'\n",
    "            current_data = []\n",
    "            for df in dataframes:\n",
    "                cur_df = df.loc[group_id].copy()\n",
    "                # returning single line dataframes from df.loc requires special handling\n",
    "                if not isinstance(cur_df, pd.DataFrame):\n",
    "                    cur_df = pd.DataFrame({a: b for a, b in zip(cur_df.index.values, cur_df.values)}, index=[group_id])\n",
    "                    cur_df.index.name = self.group_id_column\n",
    "                cur_df = cur_df.reset_index(drop=not self.export_group_id_column)\n",
    "                current_data.append(cur_df)\n",
    "            yield tuple(current_data)\n",
    "\n",
    "            while self._status != 'prediction_received':\n",
    "                print('You must call `predict()` successfully before you can continue with `iter_test()`', flush=True)\n",
    "                yield None\n",
    "\n",
    "        with open('submission.csv', 'w') as f_open:\n",
    "            pd.concat(self.predictions).to_csv(f_open, index=False)\n",
    "        self._status = 'finished'\n",
    "\n",
    "    def predict(self, user_predictions: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Accepts and stores the user's predictions and unlocks iter_test once that is done\n",
    "        \"\"\"\n",
    "        if self._status == 'finished':\n",
    "            raise Exception('You have already made predictions for the full test set.')\n",
    "        if self._status != 'prediction_needed':\n",
    "            raise Exception('You must get the next test sample from `iter_test()` first.')\n",
    "        if not isinstance(user_predictions, pd.DataFrame):\n",
    "            raise Exception('You must provide a DataFrame.')\n",
    "\n",
    "        self.predictions.append(user_predictions)\n",
    "        self._status = 'prediction_received'\n",
    "\n",
    "def make_env():\n",
    "    return MockApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def naive_predict(test_row, new_revealed_targets):\n",
    "    last_known = new_revealed_targets[(new_revealed_targets.is_consumption == test_row.is_consumption) &\n",
    "                                      (new_revealed_targets.prediction_unit_id == test_row.prediction_unit_id) &\n",
    "                                      (new_revealed_targets.datetime <= test_row.prediction_datetime - datetime.timedelta(days=2))]\n",
    "\n",
    "    last_known = last_known[last_known.datetime == last_known.datetime.max()]\n",
    "    \n",
    "    if len(last_known) == 0:\n",
    "        last_known = 0\n",
    "    else:\n",
    "        last_known = last_known.target.mean()\n",
    "    return last_known\n",
    "\n",
    "def naive_predict_batch(test_batch, new_revealed_targets):\n",
    "    target_series = test_batch.apply(lambda test_row: naive_predict(test_row, new_revealed_targets), axis=1)\n",
    "    target_series.name = 'target'\n",
    "    predict = pd.concat([test_batch['row_id'], target_series], axis=1)\n",
    "    predict.set_index('row_id', inplace=True)\n",
    "    return predict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:37.698904078Z",
     "start_time": "2023-12-14T12:46:37.698468704Z"
    }
   },
   "id": "2cd2310e1917f600"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming downloads/example_test_files/test.csv[prediction_datetime] from object to datetime...\n",
      "Transforming downloads/example_test_files/revealed_targets.csv[datetime] from object to datetime...\n",
      "Transforming downloads/example_test_files/client.csv[date] from object to datetime...\n",
      "Transforming downloads/example_test_files/historical_weather.csv[datetime] from object to datetime...\n",
      "Transforming downloads/example_test_files/forecast_weather.csv[origin_datetime] from object to datetime...\n",
      "Stripping incorrect timezone adjustments\n",
      "Transforming downloads/example_test_files/forecast_weather.csv[forecast_datetime] from object to datetime...\n",
      "Stripping incorrect timezone adjustments\n",
      "Transforming downloads/example_test_files/electricity_prices.csv[forecast_date] from object to datetime...\n",
      "Transforming downloads/example_test_files/electricity_prices.csv[origin_date] from object to datetime...\n",
      "Transforming downloads/example_test_files/gas_prices.csv[forecast_date] from object to datetime...\n",
      "Transforming downloads/example_test_files/gas_prices.csv[origin_date] from object to datetime...\n",
      "3120 2023-05-28 00:00:00+03:00 2023-05-28 23:00:00+03:00\n",
      "3168 2023-05-26 00:00:00+03:00 2023-05-26 23:00:00+03:00\n",
      "3120 2023-05-29 00:00:00+03:00 2023-05-29 23:00:00+03:00\n",
      "3168 2023-05-27 00:00:00+03:00 2023-05-27 23:00:00+03:00\n",
      "3120 2023-05-30 00:00:00+03:00 2023-05-30 23:00:00+03:00\n",
      "3120 2023-05-28 00:00:00+03:00 2023-05-28 23:00:00+03:00\n",
      "3120 2023-05-31 00:00:00+03:00 2023-05-31 23:00:00+03:00\n",
      "3120 2023-05-29 00:00:00+03:00 2023-05-29 23:00:00+03:00\n"
     ]
    }
   ],
   "source": [
    "env = make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, revealed_targets, client, historical_weather,\n",
    "     forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "    print(len(test), test.prediction_datetime.min(), test.prediction_datetime.max())\n",
    "    print(len(revealed_targets), revealed_targets.datetime.min(), revealed_targets.datetime.max())\n",
    "    env.predict(naive_predict_batch(test, revealed_targets))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:44.862690583Z",
     "start_time": "2023-12-14T12:46:37.698601965Z"
    }
   },
   "id": "6b3d4502ea85a9a"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "             target        target        target        target\ncount   3120.000000   3120.000000   3120.000000   3120.000000\nmean     397.055628    384.236975    378.323915    392.325769\nstd     1065.377391   1039.807390   1010.882205   1066.244326\nmin        0.000000      0.000000      0.000000      0.000000\n25%       10.917750     11.021250      9.075500      9.610000\n50%       70.727000     63.564000     61.553000     65.132000\n75%      334.855000    284.275000    276.308000    328.118750\nmax    10689.082000  11013.487000  10265.362000  11146.496000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target</th>\n      <th>target</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3120.000000</td>\n      <td>3120.000000</td>\n      <td>3120.000000</td>\n      <td>3120.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>397.055628</td>\n      <td>384.236975</td>\n      <td>378.323915</td>\n      <td>392.325769</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1065.377391</td>\n      <td>1039.807390</td>\n      <td>1010.882205</td>\n      <td>1066.244326</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>10.917750</td>\n      <td>11.021250</td>\n      <td>9.075500</td>\n      <td>9.610000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>70.727000</td>\n      <td>63.564000</td>\n      <td>61.553000</td>\n      <td>65.132000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>334.855000</td>\n      <td>284.275000</td>\n      <td>276.308000</td>\n      <td>328.118750</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10689.082000</td>\n      <td>11013.487000</td>\n      <td>10265.362000</td>\n      <td>11146.496000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([prediction.describe() for prediction in env.predictions], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:44.873250015Z",
     "start_time": "2023-12-14T12:46:44.864159885Z"
    }
   },
   "id": "9257ca750d73892"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "          target\nrow_id          \n2005872    2.675\n2005873  471.887\n2005874    0.000\n2005875    5.414\n2005876   13.899\n...          ...\n2008987  188.122\n2008988    0.000\n2008989   32.809\n2008990    0.000\n2008991  189.933\n\n[3120 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>row_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2005872</th>\n      <td>2.675</td>\n    </tr>\n    <tr>\n      <th>2005873</th>\n      <td>471.887</td>\n    </tr>\n    <tr>\n      <th>2005874</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2005875</th>\n      <td>5.414</td>\n    </tr>\n    <tr>\n      <th>2005876</th>\n      <td>13.899</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2008987</th>\n      <td>188.122</td>\n    </tr>\n    <tr>\n      <th>2008988</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2008989</th>\n      <td>32.809</td>\n    </tr>\n    <tr>\n      <th>2008990</th>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2008991</th>\n      <td>189.933</td>\n    </tr>\n  </tbody>\n</table>\n<p>3120 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.predictions[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:44.876592174Z",
     "start_time": "2023-12-14T12:46:44.873149574Z"
    }
   },
   "id": "a0268181810d989c"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:46:44.877250820Z",
     "start_time": "2023-12-14T12:46:44.876446183Z"
    }
   },
   "id": "7b2ce4e2b190584d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
